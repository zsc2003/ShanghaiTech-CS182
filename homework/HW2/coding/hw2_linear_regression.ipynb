{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fea3365b",
   "metadata": {},
   "source": [
    "# Homework2: Linear Regression\n",
    "\n",
    "In this assignment, we will start with utilizing scikit-learn to implement a linear regression model. Afterwards, we will be dropping scikit-learn and implementing these algorithms from scratch without the use of machine learning libraries. While you would likely never have to implement your own linear regression algorithm from scratch in practice, such a skill is valuable to have as you progress further into the field and find many scenarios where you actually may need to perform such implementations manually. Additionally, implementing algorithms from scratch will help you better understand the underlying mathematics behind each model.\n",
    "\n",
    "## Import Libraries\n",
    "\n",
    "We will be using the following libraries for this homework assignment. For the questions requiring manual implementation, the pre-existing implementations from scikit-learn should *not* be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff994506",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import operator\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e0d26e",
   "metadata": {},
   "source": [
    "## Preparing Data\n",
    "\n",
    "The file named **dataset1.csv** includes data that was generated from an n-degree polynomial with some gaussian noise. The data has 2 columns - first column is the feature (input) and the second column is its label (output). The first step is to load the data and split them into training, validation, and test sets. A reminder that the purpose of each of the splitted sets are as follows:\n",
    "\n",
    "- **Training Set**: The sample of data used to fit the model\n",
    "- **Validation Set**: The sample of data used to provide an unbiased evaluation of a model fit on the training dataset while tuning model hyperparameters.\n",
    "- **Test Set**: The sample of data used to provide an unbiased evaluation of a final model fit on the training dataset.\n",
    "\n",
    "In the section below, we load the csv file and split the data randomnly into 3 equal sets. \n",
    "\n",
    "*Note that in practice, we usually aim for around a 70-20-10 split for train, valid, and test respectively, but due to limited data in our case, we will do an even split in order to have sufficient data for evaluation* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cfdfe9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load the data and split into 3 equal sets\n",
    "data = pd.read_csv('./datasets/dataset1.csv', header=None)\n",
    "data = data.iloc[:, :-1]\n",
    "train, valid, test = np.split(data, [int(.33*len(data)), int(.66*len(data))])\n",
    "\n",
    "# We sort the data in order for plotting purposes later\n",
    "train.sort_values(by=[0], inplace=True)\n",
    "valid.sort_values(by=[0], inplace=True)\n",
    "test.sort_values(by=[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03a4edf",
   "metadata": {},
   "source": [
    "Let's take a look at what our data looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14005ecd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(train[0], train[1], s=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0c10a7",
   "metadata": {},
   "source": [
    "Let's apply a linear regression model using scikit-learn and see what the results look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0954ab39",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Reshape arrays since scikit-learn only takes in 2D arrays\n",
    "train_x = np.array(train[0])\n",
    "train_y = np.array(train[1])\n",
    "valid_x = np.array(valid[0])\n",
    "valid_y = np.array(valid[1])\n",
    "\n",
    "train_x = train_x.reshape(-1,1)\n",
    "train_y = train_y.reshape(-1,1)\n",
    "valid_x = valid_x.reshape(-1,1)\n",
    "valid_y = valid_y.reshape(-1,1)\n",
    "\n",
    "# Apply linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(train_x, train_y)\n",
    "y_pred = model.predict(train_x)\n",
    "\n",
    "# Plot the results\n",
    "plt.scatter(train_x, train_y, s=10)\n",
    "plt.plot(train_x, y_pred, color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb2ba19",
   "metadata": {},
   "source": [
    "By analyzing the line of best fit above, we can see that a straight line is unable to capture the patterns of the data. This is an example of underfitting. As seen in the latest lecture, we can generate a higher order equation by adding powers of the original features as new features. \n",
    "\n",
    "The linear model: \n",
    "\n",
    "$$y(x) = w_1 x + w_0$$\n",
    "\n",
    "can be transformed to a polynomial model such as:\n",
    "\n",
    "$$y(x) = w_2 x^2 + w_1 x + w_0$$\n",
    "\n",
    "Note that this is still considered to be linear model as the coefficients/weights associated with the features are still linear. $x^2$ is only a feature. However the curve that we would be fitting in this case is quadratic in nature.\n",
    "\n",
    "Below we show an example of a quadratic curve being fit to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a06ccef",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create polynomial features with degree 2\n",
    "polynomial_features = PolynomialFeatures(degree=2)\n",
    "x_poly = polynomial_features.fit_transform(train_x)\n",
    "\n",
    "# Apply linear regression\n",
    "model = LinearRegression()\n",
    "model.fit(x_poly, train_y)\n",
    "y_poly_pred = model.predict(x_poly)\n",
    "\n",
    "# Plot the results\n",
    "plt.scatter(train_x, train_y, s=10)\n",
    "plt.plot(train_x, y_poly_pred, color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0a79ab",
   "metadata": {},
   "source": [
    "As you can see, we get a slightly better fit with a quadratic curve. Let's use the model to make predictions on our validation set and compute the mean squared error, which is the error which we wish to minimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48944e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using pretrained model\n",
    "valid_y_poly_pred = model.predict(polynomial_features.fit_transform(valid_x))\n",
    "\n",
    "# Calculate mean squared error\n",
    "mse = mean_squared_error(valid_y, valid_y_poly_pred)\n",
    "print(\"Mean Squared Error: {}\".format(mse))\n",
    "\n",
    "# Plot the prediction results\n",
    "plt.scatter(valid_x, valid_y, s=10)\n",
    "plt.plot(valid_x, valid_y_poly_pred, color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6a380b",
   "metadata": {},
   "source": [
    "## Question 1: Polynomial Regression Using Scikit-learn [10pts]\n",
    "\n",
    "Now it is your turn! Following the same format as above, implement a 5-degree polynomial regression model on the training data and plot your results. Use your model to predict the output of the validation set and calculate the root mean square error. Report and plot the results. \n",
    "\n",
    "Grading policy:\n",
    "\n",
    "- Q1.1 [4pts]\n",
    "    - Fit a 5-degree polynomial using scikit-learn [1pts]\n",
    "    - Use model to predict output of validation set [1pts]\n",
    "    - Calculate and report the MSE [1pt]\n",
    "    - Plot curves on the training set and the validation set [1pt]\n",
    "- Q1.2 [1pts]\n",
    "- Q1.3 [4pts]\n",
    "    - Fit a 10-degree polynomial using scikit-learn [1pts]\n",
    "    - Use model to predict output of validation set [1pts]\n",
    "    - Calculate and report the MSE [1pts]\n",
    "    - Plot curves on the training set the validation set [1pt]\n",
    "- Q1.4 [1pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83440e6",
   "metadata": {},
   "source": [
    "## Q1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81f9d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE - Fit a 5-degree polynomial using scikit-learn\n",
    "# Create polynomial features with degree 5\n",
    "\n",
    "\n",
    "# Apply linear regression\n",
    "\n",
    "\n",
    "### YOUR CODE HERE - Plot your the curve on the training data set\n",
    "# Plot the training data set\n",
    "\n",
    "\n",
    "### YOUR CODE HERE - Use model to predict output of validation set\n",
    "\n",
    "\n",
    "### YOUR CODE HERE - Calculate the MSE. Report and plot the curve on the validation set.\n",
    "# Calculate mean squared error\n",
    "\n",
    "\n",
    "# Plot the prediction results on the validation set \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c263a23",
   "metadata": {},
   "source": [
    "## Q1.2 Did the mean squared error go up or down as compared to the 2-degree polynomial curve? Why do you think this is the case?\n",
    "\n",
    "**------- ANSWER HERE -----------**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76db2e1",
   "metadata": {},
   "source": [
    "## Q1.3\n",
    "Now repeat the above for a 10-degree polynomial regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ca9d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE - Fit a 10-degree polynomial using scikit-learn\n",
    "# Create polynomial features with degree 10\n",
    "\n",
    "\n",
    "# Apply linear regression\n",
    "\n",
    "\n",
    "### YOUR CODE HERE - Plot your the curve on the training data set\n",
    "# Plot the training data set\n",
    "\n",
    "\n",
    "### YOUR CODE HERE - Use model to predict output of validation set\n",
    "\n",
    "\n",
    "### YOUR CODE HERE - Calculate the MSE. Report and plot the curve on the validation set.\n",
    "# Calculate mean squared error\n",
    "\n",
    "\n",
    "\n",
    "# Plot the prediction results on the validation set\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0b87ca",
   "metadata": {},
   "source": [
    "## Q1.4 How does the mean square error compare to the polynomial regression with degree 5? Why do you think this is the case?\n",
    "\n",
    "**-------- ANSWER HERE -----------**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec677c1f",
   "metadata": {},
   "source": [
    "## Question 2: Manual Implementation [10pts]\n",
    "\n",
    "Now it's time to appreciate the hard work that open source developers have put, in order to allow you to implemenent machine learning models without doing any math! No more scikit-learn (or any other libraries like Tensorflow, Pytorch, etc) for the rest of this assignment!\n",
    "\n",
    "Your first step is to fit a **10-degree polynomial** to the dataset we have been used above. Then using your results, calculate the mean squared error on both the training and validation set. \n",
    "\n",
    "A reminder that in polynomial regression, we are looking for a solution for the equation:\n",
    "\n",
    "$$ Y(X) = W^\\top * \\phi(X), $$\n",
    "\n",
    "where\n",
    "\n",
    "$$ \\phi(X) = [ 1, X, X^2, X^3, ....., X^n ]^\\top. $$\n",
    " \n",
    "Let $\\mathbf{\\phi(X)}=[\\phi(X_1)^\\top;\\ldots;\\phi(X_n)^\\top]$ denote the data matrix after polynomail transformation and $\\mathbf{Y}$ denote the target vector. Recall the the closed-form solution for linear regression is given by normal equation, which is:\n",
    "\n",
    "$$ W = (\\mathbf{\\phi(X)}^T \\mathbf{\\phi(X)})^{-1}\\mathbf{\\phi(X)}^\\top \\mathbf{Y}. $$\n",
    "\n",
    "Make sure to review the slides, do some research, and/or ask for clarification if this doesn't make sense. You must understand the underlying math before being able to implement this properly.\n",
    "\n",
    "*Suggestion - Use the original pandas dataframes variables named train, valid, and test instead of the reshaped arrays that were used specifically for scikit-learn. It will make your computations cleaner and more inuitive.*\n",
    "\n",
    "Grading policy:\n",
    "- Q2.1 [4pts]\n",
    "    - Create the polynomial matrix $\\phi(X)$ [1pts]\n",
    "    - Find the weighted matrix W by normal equation [1pts]\n",
    "    - Make predictions on the training set, calculate and report the mean squared error [1pts]\n",
    "    - Make predictions on the validation set, calculate and report the mean squared error [1pts]\n",
    "- Q2.2 [6pts]\n",
    "    - Implement gradient decent manually [6pts]\n",
    "        - Correctness of the gradient [2pts]\n",
    "        - Correctness of the update in each iteration [2pts]\n",
    "        - Convergence of the algorithm [1pts]\n",
    "        - Calculate and report the mean squared error on both training and validation set [1pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee1ae03",
   "metadata": {},
   "source": [
    "## Q2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d568d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE - Create the polynomial matrix \\phi(X), which is a numpy array\n",
    "# phi_x = []   # modify this line\n",
    "\n",
    "\n",
    "\n",
    "### YOUR CODE HERE - Find the weighted matrix W by normal equation\n",
    "\n",
    "\n",
    "\n",
    "### YOUR CODE HERE - Make predictions on the training set and calculate the mean squared error.\n",
    "\n",
    "\n",
    "# ==============================\n",
    "\n",
    "print(\"Mean Squared Error (Training): {}\".format(mse_trian))\n",
    "plt.scatter(train_x, train_y, s=10)\n",
    "plt.plot(train_x,pred_y_train,color='r')\n",
    "plt.show()\n",
    "\n",
    "### YOUR CODE HERE - Make predictions on the validation set and calculate the mean squared error.\n",
    "\n",
    "\n",
    "# ==============================\n",
    "\n",
    "print(\"Mean Squared Error (Validation): {}\".format(mse_valid))\n",
    "plt.scatter(valid_x, valid_y, s=10)\n",
    "plt.plot(valid_x,pred_y_valid,color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1ee9d3",
   "metadata": {},
   "source": [
    "For the rest of the assignment, we will use the other dataset named **dataset2.csv**. First load the csv and split the model into train, valid, and test sets as shown earlier in the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31971a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset2.csv and split into 3 equal sets\n",
    "data = pd.read_csv('./datasets/dataset2.csv', header=None)\n",
    "data = data.iloc[:, :-1]\n",
    "train, valid, test = np.split(data, [int(.33*len(data)), int(.66*len(data))])\n",
    "# Sort the data in order for plotting purposes later\n",
    "train.sort_values(by=[0], inplace=True)\n",
    "valid.sort_values(by=[0], inplace=True)\n",
    "test.sort_values(by=[0], inplace=True)\n",
    "\n",
    "train_x = np.array(train[0])\n",
    "train_y = np.array(train[1])\n",
    "valid_x = np.array(valid[0])\n",
    "valid_y = np.array(valid[1])\n",
    "test_x = np.array(test[0])\n",
    "test_y = np.array(test[1])\n",
    "train_x = train_x.reshape(-1, 1)\n",
    "train_y = train_y.reshape(-1, 1)\n",
    "valid_x = valid_x.reshape(-1, 1)\n",
    "valid_y = valid_y.reshape(-1, 1)\n",
    "test_x = test_x.reshape(-1, 1)\n",
    "test_y = test_y.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fdd429",
   "metadata": {},
   "source": [
    "Plot the data below to see what it looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6bdca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('train set')\n",
    "plt.scatter(train_x, train_y, s=10)\n",
    "plt.show()\n",
    "plt.title('valid set')\n",
    "plt.scatter(valid_x, valid_y, s=10)\n",
    "plt.show()\n",
    "plt.title('test set')\n",
    "plt.scatter(test_x, test_y, s=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b7e35d",
   "metadata": {},
   "source": [
    "## Q2.2\n",
    "\n",
    "If done properly, you should see that the points fall under a relatively straight line with minor deviations. Looks like a perfect example to implement a linear regression model using the **gradient descent** method ..... without the use of any machine learning libraries!\n",
    "\n",
    "Since the data falls along a straight line, we can assume the solution follows the form:\n",
    "\n",
    " $$ y(x) = w x + b $$\n",
    "\n",
    "A reminder that in gradient descent, we essentially want to iteratively get closer to the minimum of our objective function (the mean squared error), such that:\n",
    " \n",
    "$$ MSE(w_0) > MSE(w_1) > MSE(w_2) > ... $$\n",
    "\n",
    "The algorithm is as follows:\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ** 1) Pick initial $w_0$ randomnly. **\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ** 2) For $k=1,2..$ $\\Rightarrow$ $w_{k+1}$ = $w_k$ - $\\alpha$  $g(w_k)$  where $\\alpha > 0$ is the learning rate and $g(w_k)$ is the gradient. **\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ** End when | $w_{k+1}$ - $w_k$ | < $\\epsilon$ **\n",
    "\n",
    "\n",
    "There are many resources online for gradient descent. You must understand the underlying math before being able to implement this properly.\n",
    "\n",
    "Now once you understand, it is time to implement the gradient descent below. You may set the learning rate to 1e-6 or whatever value you think is best. As usual, calculate the mean squared error and plot your results. This time, training should be done using the training and validation sets, while the final mean squared error should be computed using the testing set.\n",
    "\n",
    "**Feel Free to modify the existing code, or just ignore it and provide your own implementation!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf9ada6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Implement gradient decent\n",
    "m = 1  # initial w (slope)\n",
    "b = 1  # initial b (intercept)\n",
    "temp_m = 0\n",
    "temp_b = 0 \n",
    "lr = 1e-6\n",
    "epsilon = 1e-9\n",
    "epsilon_valid = 1e-12\n",
    "lr_decay = 0.9\n",
    "epsilon_lr = 0.2\n",
    "\n",
    "def get_mse(m,b,x,y):\n",
    "    return np.sum(np.multiply((y - m * x - b),(y - m * x - b))) / len(x)\n",
    "\n",
    "# ======== YOUR CODE HERE ======\n",
    "\n",
    "\n",
    "# ==============================\n",
    "\n",
    "### Calculate the mean squared error on both training and validation set and plot the results.\n",
    "print(\"Mean Squared Error (Training): {}\".format(get_mse(final_m,final_b,train_x,train_y)))\n",
    "print(\"Mean Squared Error (Testing): {}\".format(get_mse(final_m,final_b,test_x,test_y)))\n",
    "pred_y_test = m * test_x + b\n",
    "plt.scatter(test_x, test_y, s=10)\n",
    "plt.plot(test_x,pred_y_test,color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2a0387",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
